\chapter{Implementazione del Sistema}
\label{chap:chap4}

Nel capitolo seguente vengono riportati alcuni snippet di codice selezionati, utili per illustrare le parti più rilevanti dell'implementazione. Per consultare il codice completo si rimanda alla repository indicata nell'Appendice~\ref{chap:app2}.

\section{Architettura del Sistema}

Il sistema di raccomandazione fuzzy è stato implementato seguendo un'architettura modulare e scalabile, progettata per supportare esperimenti sistematici e riproducibili. L'architettura è organizzata in quattro livelli principali:

\begin{itemize}
    \item \textbf{Livello di Configurazione}: Gestione centralizzata dei parametri sperimentali
    \item \textbf{Livello di Orchestrazione}: Coordinamento del flusso di esecuzione degli esperimenti
    \item \textbf{Livello di Elaborazione}: Componenti per clustering, valutazione e visualizzazione
    \item \textbf{Livello di Utilità}: Funzioni di supporto per caricamento, preprocessamento e normalizzazione
\end{itemize}

\subsection{Pipeline Sperimentale}
Il flusso completo di un esperimento è:

\begin{enumerate}
    \item \textbf{Caricamento Configurazione}: Lettura parametri da JSON
    \item \textbf{Preparazione Dati}: Caricamento, filtro, split train/test
    \item \textbf{Loop Parametri}: Per ogni combinazione di:
        \begin{itemize}
            \item Normalizzazione
            \item Numero di cluster
            \item Parametro di fuzziness
            \item Metodo di clustering
            \item Strategia di defuzzificazione
            \item Selezione vicini
        \end{itemize}
    \item \textbf{Clustering}: Applicazione algoritmo selezionato
    \item \textbf{Predizione}: Calcolo rating predetti
    \item \textbf{Valutazione}: Calcolo RMSE e MAE
    \item \textbf{Visualizzazione}: Generazione grafici
    \item \textbf{Salvataggio}: Risultati e configurazioni
\end{enumerate}

\section{Esecuzione del Sistema}

Il sistema utilizza un file di configurazione JSON centralizzato (\texttt{config/config.json}) che controlla tutti gli aspetti dell'esperimento:

\begin{lstlisting}[language=json, caption=Esempio di configurazione]
{
    "dataset_name": "ml-100k",
    "normalizations": ["simple_centering", "zscore_per_user", 
                      "minmax_per_user", "no_normalization"],
    "cluster_values": [4, 6, 8],
    "m_values": [1.5, 2.0, 2.5],
    "clustering_methods": ["fcm", "kmeans"],
    "defuzzification_methods": ["maximum", "cog"],
    "neighbor_selection_methods": ["none", "pearson"],
    "min_user_ratings": 150,
    "min_item_ratings": 150,
    "test_size": 0.2,
    "max_iter": 3000,
    "error": 1e-06
}
\end{lstlisting}

Questa configurazione consente di sviluppare le analisi in modo rapido e modulare, poiché tutti i parametri rilevanti sono centralizzati in un unico file di configurazione. In questo modo, è possibile modificare facilmente le impostazioni degli esperimenti senza intervenire direttamente sul codice, riducendo il rischio di errori e migliorando l’efficienza del processo di sviluppo.
Sebbene quando si utilizza K-Means variare il parametro di fuzziness e metodo di defuzzificazione non abbiano impatto, è risultato più veloce mantenerli nel file di configurazione ed eseguirli piuttosto che gestire il caso specifico.


\subsection{Orchestrazione degli Esperimenti}

La classe \texttt{Runner} rappresenta il componente centrale di orchestrazione, in quanto è la classe che si occupa di:
\begin{itemize}
    \item Caricare la configurazione da eseguire
    \item Creazione la directory in cui salvare i risultati
    \item Eseguire tutte le combinazioni dei parametri
    \item Salvare i risultati ottenuti e la configurazione utilizzata
\end{itemize}


\begin{lstlisting}[style=PythonStyle, caption=estratti della classe Runner]
class Runner:
    def __init__(self, config_path):
        self.config = ConfigManager(config_path).load()
        timestamp_format = self.config.get("run_timestamp_format", 
                                         "run_%Y_%m_%d_%H_%M_%S")
        run_timestamp = datetime.now().strftime(timestamp_format)
        base_output_dir = os.path.join(self.config.get("output_dir", "output"), 
                                      run_timestamp)
        
        self.config["images_dir"] = os.path.join(base_output_dir, 
                                                self.config.get(
                                                "images_subdir", "images"))
        self.config["results_dir"] = os.path.join(base_output_dir, 
                                                 self.config.get(
                                                 "results_subdir", "results"))
        
        self.data_manager = DataManager(self.config)
        self.result_manager = ResultManager(self.config)

    def run(self):
        R_train, R_test_aligned = self.data_manager.load_and_preprocess()

        for norm_name in normalizations:
            for c in cluster_values:
                for m in m_values:
                    for clustering_method in clustering_methods:
                        for defuzz_method in defuzz_methods:
                            for neighbor_method in neighbor_methods:
                                experiment = Experiment(...)
                                metrics = experiment.run()
                                results[norm_name][str(c)]
                                    [str(m)][clustering_method]
                                    [defuzz_method][neighbor_method] = metrics

        self.result_manager.save_results(results)
\end{lstlisting}

\subsection{Gestione Dati}

Il \texttt{DataManager}, una volta chiamato dalla classe \texttt{Runner}, si occupa di due mansioni principali:
\begin{enumerate}
    \item Caricare e Preprocessare i dati, tramite il metodo \texttt{load\_and\_preprocess}
    \item Normalizzare i dati, tramite il metodo \texttt{normalize}
\end{enumerate}

Il primo metodo si occupa di:
\begin{itemize}
    \item Scegliere quale dataset utilizzare, in base al nome specificato nel file di configurazione
    \item Chiamare il filtro per rimuovere utenti con meno di \texttt{min\_user\_rating} rating e item con meno di \texttt{min\_user\_rating} rating, 
    \item Eseguire lo split di train size e test size in base al parametro specificato nel file di configurazione
    \item Allineare il test set affinchè le matrici di train e test abbiano stessa dimensione
\end{itemize}

\begin{lstlisting}[style=PythonStyle, caption=Metodo load\_and\_preprocess del DataManager]
def load_and_preprocess(self):
    if self.config.get('dataset_name') == 'ml-1m':
        _, R = load_data_1m()
    else:
        _, R = load_data_100k()
    
    R_dense = filter_dense(R, 
                          self.config['min_user_ratings'], 
                          self.config['min_item_ratings'])
    
    R_train, R_test = split_train_test_per_user(
        R_dense, 
        test_size=self.config['test_size'], 
        random_state=self.config['random_state']
    )
    
    R_test_aligned = R_test.reindex(columns=R_train.columns, 
                                   fill_value=np.nan)
    return R_train, R_test_aligned
\end{lstlisting}

Il secondo metodo si occupa di:
\begin{itemize}
    \item Utilizzare la funzione di normalizzazione corretta
    \item Calcolare la media globale dei rating nel dataset di training
    \item Controlla se la media dell'utente è valia
    \item Se l'utente ha media valida la usa, altrimenti usa la media globale
\end{itemize}

\begin{lstlisting}[style=PythonStyle, caption=Metodo normaliza del DataManager]
def normalize(self, R_train, R_test_aligned, norm_func=None):
    if norm_func is not None:
        R_train_norm = norm_func(R_train)
        R_test_norm = norm_func(R_test_aligned)
    else:
        R_train_norm = R_train.astype(float)
        R_test_norm = R_test_aligned.astype(float)
    
    global_mean = R_train_norm.stack().mean()
    R_train_filled = R_train_norm.apply(lambda row: row.fillna(row.mean() if not np.isnan(row.mean()) else global_mean), axis=1)
    R_test_filled = R_test_norm.apply(lambda row: row.fillna(row.mean() if not np.isnan(row.mean()) else global_mean), axis=1)
    return R_train_filled, R_test_filled
\end{lstlisting}

\subsection{Normalizzazione}

Il sistema implementa quattro strategie di normalizzazione nel modulo \texttt{normalizer.py}:

\begin{enumerate}
    \item \textbf{Simple Centering}: sottrae la media delle valutazioni di ogni utente da tutte le sue valutazioni, centrando dunque i dati attorno allo zero.

    \[
    r'_{ui} = r_{ui} - \bar{r_u}
    \]
    dove $\bar{r_u}$ è la media delle valutazioni dell’utente $u$.

    \begin{lstlisting}[style=PythonStyle, caption=Normalizzazione: Simple Centering]
def simple_centering(R):
    user_means = R.mean(axis=1)
    return R.subtract(user_means, axis=0).astype(float)
    \end{lstlisting}
    
    \item \textbf{Z-score per utente}: calcola media e deviazione standard delle valutazioni di ogni utente. Ad ogni valutazione si sottrae la media come in simple centering, ma si divide anche per la deviazione standard, normalizzando non solo la scala ma anche la variabilità delle valutazioni.

    \[
    r'_{ui} = \frac{r_{ui} - \bar{r_u}}{\sigma_u}
    \]
    dove $\bar{r_u}$ è la media e $\sigma_u$ la deviazione standard delle valutazioni dell’utente $u$.

    \begin{lstlisting}[style=PythonStyle, caption=Normalizzazione: Z-Score]
def zscore_per_user(R):
    R_norm = R.copy()
    for user in R_norm.index:
        user_ratings = R_norm.loc[user].dropna()
        if len(user_ratings) > 1 and user_ratings.std() > 0:
            mean_val = user_ratings.mean()
            std_val = user_ratings.std()
            R_norm.loc[user] = (R_norm.loc[user] - mean_val) / std_val
    return R_norm.fillna(0).astype(float)
    \end{lstlisting}
    
    \item \textbf{Min-Max per utente}: trovando il valore minimo e massimo delle valutazioni di ogni utente e poi applicando la formula (valore - min) / (max - min), scala le valutazioni di ogni utente nell'intervallo [0,1].

    \[
    r'_{ui} = \frac{r_{ui} - \min_u}{\max_u - \min_u}
    \]
    dove $\min_u$ e $\max_u$ sono rispettivamente il valore minimo e massimo delle valutazioni dell’utente $u$.

    \begin{lstlisting}[style=PythonStyle, caption=Normalizzazione: Min-Max]
def minmax_per_user(R):
    R_norm = R.copy()
    for user in R_norm.index:
        user_ratings = R_norm.loc[user].dropna()
        if len(user_ratings) > 1:
            min_val = user_ratings.min()
            max_val = user_ratings.max()
            if max_val > min_val:
                R_norm.loc[user] = (R_norm.loc[user] - min_val) / (max_val - min_val)
    return R_norm.astype(float).fillna(0)
    \end{lstlisting}
    
    \item \textbf{Nessuna normalizzazione}: mantenimento dei valori originali.
\end{enumerate}


\subsection{Algoritmi di Clustering}

Il sistema, all'interno della classe \texttt{Clusterer} implementa due algoritmi di clustering per la segmentazione degli utenti:

\subsubsection{Fuzzy C-Means (FCM)}
L'algoritmo Fuzzy C-Means è stato scelto come metodo principale per la sua capacità di gestire l'incertezza nelle assegnazioni degli utenti ai cluster. A differenza del K-Means tradizionale, FCM assegna a ogni utente un grado di membership (valore tra 0 e 1) per ogni cluster, riflettendo la natura sfumata delle preferenze degli utenti. Questo approccio è particolarmente adatto ai sistemi di raccomandazione dove gli utenti possono avere gusti ibridi o appartenere parzialmente a più categorie.

L'obiettivo dell’algoritmo Fuzzy C-Means è minimizzare la seguente funzione di costo:

\[
J_m = \sum_{u=1}^{N} \sum_{c=1}^{C} u_{cu}^m \cdot \lVert x_u - v_c \rVert^2
\]

dove:
\begin{itemize}
    \item $m > 1$ è il parametro di fuzzificazione
    \item $u_{cu}$ è la membership dell’utente $u$ al cluster $c$
    \item $x_u$ è il vettore di caratteristiche dell’utente $u$
    \item $v_c$ è il centroide del cluster $c$
    \item $\lVert \cdot \rVert$ indica la norma euclidea
\end{itemize}

L'implementazione del Fuzzy C-Means utilizza la libreria \texttt{skfuzzy}:

\begin{lstlisting}[style=PythonStyle, caption=Implementazione FCM]
def fcm_cluster(self, X, n_clusters, m, error, max_iter, seed):
    cntr, u, _, _, _, _, _ = fuzz.cmeans(
        data=X.T,           # Trasposizione per skfuzzy
        c=n_clusters,       # Numero di cluster
        m=m,                # Parametro di fuzziness
        error=error,        # Criterio di convergenza
        maxiter=max_iter,   # Iterazioni massime
        seed=seed           # Seed per riproducibilita'
    )
    return cntr, u
\end{lstlisting}

\subsubsection{K-Means}
L'algoritmo K-Means è stato incluso come baseline per confronto, implementando clustering hard dove ogni utente appartiene esclusivamente a un singolo cluster. Questo approccio tradizionale serve come punto di riferimento per valutare i benefici dell'approccio fuzzy, permettendo di quantificare l'impatto della gestione dell'incertezza nelle assegnazioni dei cluster.

La funzione obiettivo del K-Means da minimizzare è:

\[
J = \sum_{u=1}^{N} \lVert x_u - v_{c(u)} \rVert^2
\]

dove $c(u)$ è il cluster assegnato all’utente $u$.

Di seguito viene fornita l'implementazione del K-Means standard:

\begin{lstlisting}[style=PythonStyle, caption=Implementazione K-Means]
def kmeans_cluster(self, X, n_clusters, seed):
    kmeans = sklearn.cluster.KMeans(n_clusters=n_clusters, 
                                   random_state=seed)
    labels = kmeans.fit_predict(X)
    cntr = kmeans.cluster_centers_
    
    u = np.zeros((n_clusters, X.shape[0]))
    u[labels, np.arange(X.shape[0])] = 1
    return cntr, u
\end{lstlisting}

\subsubsection{Predizione Rating}
La predizione dei rating è necessaria nei sistemi di raccomandazione fuzzy in quanto, dopo aver ottenuto i cluster degli utenti attraverso gli algoritmi di clustering, il sistema utilizza i centroidi dei cluster e le membership degli utenti per generare le predizioni dei rating mancanti.

Il processo di predizione segue questi passaggi:

\begin{enumerate}
    \item \textbf{Calcolo dei Centroidi}: I centroidi rappresentano il profilo medio di preferenze per ogni cluster
    \item \textbf{Utilizzo delle Membership}: Le membership fuzzy determinano quanto ogni utente contribuisce a ciascun cluster
    \item \textbf{Predizione Pesata}: Le predizioni finali sono calcolate come media pesata dei centroidi, dove i pesi sono le membership
\end{enumerate}

La predizione di un rating avviene combinando le appartenenze fuzzy dell’utente ai cluster e i centroidi dei cluster relativi agli item. La formula generale è:

\[
\hat{r}_{ui} = \sum_{c=1}^{C} u_{cu} \cdot v_{ci}
\]

dove:
\begin{itemize}
    \item $\hat{r}_{ui}$ è il rating predetto per l’utente $u$ sull’item $i$
    \item $u_{cu}$ è il grado di appartenenza dell’utente $u$ al cluster $c$
    \item $v_{ci}$ è il valore associato all’item $i$ nel centroide del cluster $c$
    \item $C$ è il numero totale di cluster
\end{itemize}


\begin{lstlisting}[style=PythonStyle, caption=Algoritmo di predizione della classe Clusterer]
def predict(self, cntr, membership):
    n_clusters, n_users = membership.shape
    n_items = cntr.shape[1]
    pred = np.zeros((n_users, n_items))
    
    for c in range(n_clusters):
        weights = membership[c, :] 
        pred += np.outer(weights, cntr[c, :])

    return pred
\end{lstlisting}

Infine, la classe \texttt{Clusterer} calcola la membership di utenti mai visti usando i centroidi addestrati, tramite il metodo \texttt{predict\_test}.
\begin{lstlisting}[style=PythonStyle, caption=Calcolo della Membership in fase di test]
def predict_test(self, R_test_scaled, cntr, m, error, max_iter):
    u_test, _, _, _, _, _ = fuzz.cmeans_predict(
        R_test_scaled.T, cntr, m, error=error, maxiter=max_iter)
    return u_test
\end{lstlisting}

\subsection{Strategie di Defuzzificazione}

Le strategie di defuzzificazione convertono le membership fuzzy, ovvero valori continui tra 0 e 1, in decisioni discrete o valori crisp, cioè in un valore preciso e definito. Questo viene effettuato per poter facilitare l'interpretazione dei dati e permettere di prendere decisioni finali, come determinare a quale cluster appartiene ciascun utente. 

Il sistema implementa due strategie principali di defuzzificazione:

\begin{enumerate}
    \item \textbf{Metodo del Massimo}: Assegna ogni utente al cluster con membership massima, approccio più conservativo che privilegia la certezza.
\begin{lstlisting}[style=PythonStyle, caption=Defuzzificazione per massimo]
def defuzzify_maximum(membership):
    return np.argmax(membership, axis=0)
\end{lstlisting}
    \item \textbf{Center of Gravity (COG)}: Calcola un indice continuo come media pesata delle membership, mantenendo la natura fuzzy.
\begin{lstlisting}[style=PythonStyle, caption=Defuzzificazione COG]
def defuzzify_cog(membership):
    cluster_indices = np.arange(membership.shape[0]).reshape(-1, 1)
    cog = np.sum(membership * cluster_indices, axis=0) / np.sum(membership, axis=0)
    return cog
\end{lstlisting}
\end{enumerate}

\subsection{Selezione dei Vicini}

La selezione dei vicini è una strategia opzionale che permette di filtrare gli utenti candidati per il calcolo delle raccomandazioni basandosi su criteri di similarità. 

Il sistema supporta due modalità di selezione:
\begin{enumerate}
    \item \textbf{Nessuna Selezione}: Considera tutti gli utenti nel cluster, approccio più inclusivo ma potenzialmente rumoroso.
    \item \textbf{Correlazione di Pearson}: Filtra gli utenti basandosi sulla correlazione delle loro valutazioni, approccio più selettivo che privilegia la similarità.
\begin{lstlisting}[style=PythonStyle, caption=Selezione vicini Pearson]
def select_pearson_neighbors(user_vector, candidate_matrix, threshold=0.5):
    indices = []
    pearson_values = []
    
    for idx, candidate in enumerate(candidate_matrix):
        mask = ~np.isnan(user_vector) & ~np.isnan(candidate)
        if np.sum(mask) < 2:
            continue
        
        r_tuple = pearsonr(user_vector[mask], candidate[mask])
        r = r_tuple[0]
        
        if not isinstance(r, (float, int)) or np.isnan(r):
            continue
        
        if r > threshold:
            indices.append(idx)
            pearson_values.append(r)
    
    return np.array(indices), np.array(pearson_values)
\end{lstlisting}
\end{enumerate}


\section{Valutazione e Visualizzazione delle Performance}

Una volta implementata la pipeline esecutiva del programma, si è resa necessaria una fase di valutazione delle performance ottenibili.

Le metriche utilizzate a tal fine sono:
\begin{itemize}
    \item \textbf{RMSE (Root Mean Square Error)}: Penalizza maggiormente gli errori grandi, utile per identificare predizioni molto inaccurate
    \item \textbf{MAE (Mean Absolute Error)}: Fornisce una misura più robusta degli errori, meno sensibile agli outlier
\end{itemize}

La valutazione viene eseguita sia sui dati di test che su quelli di training per analizzare la capacità del modello di generalizzare su dati non visti e per monitorare eventuali fenomeni di overfitting.

\begin{lstlisting}[style=PythonStyle, caption=Calcolo metriche di valutazione]
def evaluate(self, y_true, y_pred):
    y_true = np.array(y_true, dtype=np.float64)
    y_pred = np.array(y_pred, dtype=np.float64)
    
    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)
    
    mse = mean_squared_error(y_true[mask], y_pred[mask])
    mae = mean_absolute_error(y_true[mask], y_pred[mask])
    
    return np.sqrt(mse), mae
\end{lstlisting}

Il sistema include un modulo di visualizzazione completo (\texttt{Plotter.py}) che genera:

\begin{enumerate}
    \item \textbf{Cluster PCA}: Visualizzazione 2D dei cluster utente
    \item \textbf{Istogrammi di Membership}: Distribuzione dei valori di membership massimi
    \item \textbf{Heatmap di Membership}: Matrice di membership per utenti incerti
    \item \textbf{Confronti tra Normalizzazioni}: Plot riassuntivo con PCA, Max Membership e Data Distribution
\end{enumerate}

Infine, vista la grande mole di plot ottenuti, il modulo \texttt{aggregate\_plotter.py} genera visualizzazioni comparative come:

\begin{itemize}
    \item \textbf{Barplot Top-N}: Migliori configurazioni per ogni metrica
    \item \textbf{Heatmap}: Performance per cluster e normalizzazione
    \item \textbf{Boxplot}: Distribuzione delle metriche per metodo di clustering
    \item \textbf{Summary}: File di testo con i top-n migliori risultati per ogni combinazione di metrica (RMSE, MAE) e fase (train, test)
\end{itemize}

\subsection*{Confronto con Letteratura}

L'analisi svolta in~\cite{KOOHI2016134}, su cui tale lavoro si basa, propone un sistema di raccomandazione collaborativo user-based basato su clustering, confrontando l'efficacia di tre tecniche: K-means, Self-Organizing Map (SOM) e Fuzzy C-means (FCM). L’analisi si concentra sull’accuratezza della raccomandazione in termini di accuracy, precision e recall, utilizzando la metrica di similarità di Pearson  e media delle valutazione come tecniche di predizione due metodi di defuzzificazione: massimo e centro di gravità. Il dataset utilizzato è MovieLens 100k, con valutazione basata su una procedura di \textit{5-fold cross-validation}.

Il sistema proposto in questo lavoro si differenzia sotto alcuni aspetti. Osservando che SOM offre prestazioni inferiori rispetto a FCM, è stato deciso di ometterlo e limitarsi a un algoritmo per hard clustering e uno per fuzzy clustering. Stesso discorso vale per la tecnica di predizione delle valutazioni mediante media. Infine, non è stato implementato la valutazione tramite fold. In aggiunta, invece, vengono implementati 3 metodi di normalizzazione, gestione dei vincoli minimi su utenti e item, controllo del parametro di fuzzificazione \( m \), introduzione di rumore artificiale e definizione personalizzata della suddivisione train/test.

La Tabella~\ref{tab:confronto_parametri} riassume le principali differenze tra i due approcci.

\begin{table}[H]
\centering
\caption{Confronto dei parametri sperimentali tra questo lavoro e Koohi \& Kiani (2016)}
\resizebox{\textwidth}{!}{%
\label{tab:confronto_parametri}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Parametro / Funzionalità} & \textbf{Koohi \& Kiani (2016)} & \textbf{Questo lavoro} \\
\hline
Algoritmi di clustering & K-means, SOM, FCM & K-means, FCM \\
\hline
Numero di cluster & Sì (da 3 a 15) & Sì (valore configurabile) \\
\hline
Parametro $m$ & No & Sì (configurabile) \\
\hline
Metodi di predizione & Average, Pearson & Pearson \\
\hline
Metriche di valutazione & Accuracy, Precision, Recall & RMSE, MAE, Precision, Recall, Accuracy, F1-score \\
\hline
Metodi di defuzzificazione & Max, Center of Gravity & Max, Center of Gravity \\
\hline
Tecniche di normalizzazione & No & 3 (centering, min-max, z-score) \\
\hline
Filtro su utenti/item minimi & No & Sì \\
\hline
Introduzione di rumore nei dati & No & Sì (valore configurabile) \\
\hline
Train/Test & 5-fold & Dimensione split configurabile \\
\hline
Selezione della similarità & Pearson, Media & Pearson \\
\hline
\end{tabular}%
}
\end{table}
